<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><style type=text/css>body{font-family:monospace}</style><title>Processing Audio Files with Amazon Transcribe</title><link rel=stylesheet href=/css/style.css></head><body><header>===================<br>== <a href=/>Nathan's Blog</a> ==<br>===================<div style=float:right>infrequent posts about things I am working on</div><br><p><nav><a href=/><b>Start</b></a>.
<a href=/family-culture/><b>Family Culture</b></a>.
<a href=/post/><b>Posts</b></a>.
<a href=/categories/><b>Categories</b></a>.
<a href=/tags/><b>Tags</b></a>.
<a href=/about/><b>About</b></a>.</nav></p></header><main><article><h1>Processing Audio Files with Amazon Transcribe</h1><b><time>31.12.2019 21:41</time></b>
<a href=/tags/amazon>amazon</a>
<a href=/tags/aws>aws</a>
<a href=/tags/interviews>interviews</a>
<a href=/tags/oral-history>oral history</a>
<a href=/tags/transcribe>transcribe</a>
<a href=/tags/transcription>transcription</a><div><p>I have been working on collecting a family’s oral history for the past few months. During the process I took notes with simple descriptions of what the speaker was describing or telling and a rough timestamp of when in the file the conversation took place. After collecting hours of stories, I realized that having a transcription would make things much easier to search and perhaps more useful to those interested in these particular histories. Why not get a transcription of the contents via one of the cloud offerings? Amazon offers a service called Transcribe that is available via the AWS suite of services. Since I have a small account and some credits to burn I figured why not kick the tires and see how Transcribe would perform on meandering oral history interviews. But before I jump into the how, let me describe my particular use case.</p><p>Over the course of a few months, I have collected several half hour to two hour long interviews via multiple recording set ups. Some files were captured with <a href=https://obsproject.com/>Open Broadcast Software</a> (OBS) and include video. Others were captured using a TASCAM field recorder and are .wav files. In order to get the audio of each interview put together and normalized, I used a free application called <a href=https://www.ocenaudio.com/whatis>ocenaudio</a>. It allowed me to load .flac, .wav, and other audio formats in the same editing channels and add various effects to sections or the entire workspace. Ocenaudio’s interface allows for simple drag-and-drop editing of sound files. It is also worth noting that Ocenaudio is non-destructive meaning it leaves the original audio file alone. This can be a little confusing if you are not used to using software that performs non-destructive editing. When a project is saved, is exports the results to a new file. Keep that in mind if you plan on adding additional files later.</p><p>After I collected and normalized all the sound files, I decided to turn to AWS to get a transcription. Transcribe limits the processing size to files to 2GB. The first collection of interviews was about 3 hours long and 2.5GB in size. I split the collection up into two smaller sizes. AWS needs the file to be uploaded to S3 in order for Transcribe to access it. Here is how I set up the S3 bucket with the audio file.</p><ul><li>Place it in a region near your house. Or don’t, its up to you.</li><li>Give the S3 bucket a unique name. You can do what ever you like as long as it conforms to the <a href=https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-s3-bucket-naming-requirements.html>S3 naming standard.</a></li><li>Block <em>all</em> public access</li><li>Encrypt the bucket. I used AES-256 encryption</li><li>Give read and write access to your AWS account.</li><li>Set the S3 bucket to Intelligent Tiering storage class. It does not matter too much unless you forget to spin the bucket down in which case Intelligent Tiering will push the storage into lower cost, slow storage.</li><li>Upload the file. As long as the files are less than 50GB, you can use the browser upload tool. Otherwise, you will need to download, configure, and use the <a href=https://docs.aws.amazon.com/cli/index.html>command line utility</a>.</li></ul><p>Once your file is uploaded to S3, select the checkbox next to it and copy the “Object URL.” Transcribe needs this in order to find and process the file. If these steps do not work, check the <a href=https://aws.amazon.com/getting-started/tutorials/create-audio-transcript-transcribe/>AWS tutorial</a> on connecting an S3 bucket to a Transcribe instance.</p><p><figure><img src=https://d1.awsstatic.com/tmt/create-audio-transcript-transcribe/create-audio-transcript-transcribe-step-1l.c161c6a2c1946837a566cae724ce845fab478a3a.png alt></figure>Screenshot from the AWS tutorial</p><p>Once the files are available in S3, setting up a Transcribe job is straightforward. The following needs to be configured for Transcribe to create a job.</p><ul><li>Name of the job</li><li>The language of the interviews. I processed English but would love to hear someone’s experience processing other languages.</li><li>The location of the input file. That object URL you copied earlier.</li><li>The location of where the output should go. I used Amazon’s default.</li></ul><p>That is it! Jobs take a little while to run. Mine took about 20 minutes for audio files that are an hour long. Your mileage may vary. The results can be downloaded as a JSON file. A sample JSON object returned from Transcribe would be:</p><p>Parsing the JSON object is all that is left for doing something useful with the transcript. My Transcribe results were not stellar. I believe that was due to the fact that those people I interviewed have an accent and the vocabulary used would sometimes be in another language. The service did do two things well. It identified the various speakers on the tape correctly and when I spoke, as the interviewer, it was able to correctly catch most of what I said. So if your audio files have native English speakers, this service does a fairly decent job. You will likely need to do some significant post processing to transform the transcript into a useful document.</p></div></article></main><aside><div><div><h3>LATEST POSTS</h3></div><div><ul><li><a href=/post/2025-03-28-family-technology-use/>Family Technology Use</a></li><li><a href=/post/2022-02-10-optimize-for-loops/>Timing Execution to Help Optimize for Loops</a></li><li><a href=/post/2021-12-30-file-like-objects-in-lambda/>Working With File Like Objects in Lambda</a></li><li><a href=/post/2021-08-31-upload-pandas-df-to-s3/>Upload a Pandas Dataframe to AWS S3 With Ease</a></li><li><a href=/post/2021-08-16-moving-my-blog-to-hugo/>Moving My Personal Blog From Wordpress to Hugo</a></li></ul></div></div></aside><footer><p>&copy; 2025 <a href=/><b>Nathan's Blog</b></a>.
<a href=https://github.com/nmaynes><b>Github</b></a>.
<a href=https://twitter.com/nathanmaynes><b>Twitter</b></a>.</p></footer></body></html>
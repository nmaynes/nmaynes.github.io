<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Nathan's Blog</title><link>/</link><description>Recent content on Nathan's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 10 Feb 2022 22:03:13 -0500</lastBuildDate><atom:link href="/index.xml" rel="self" type="application/rss+xml"/><item><title>Timing Execution to Help Optimize for Loops</title><link>/post/2022-02-10-optimize-for-loops/</link><pubDate>Thu, 10 Feb 2022 22:03:13 -0500</pubDate><guid>/post/2022-02-10-optimize-for-loops/</guid><description>I was working on optimizing some code that contained a series of loops. I began my analysis by running a few different versions of the program and timing each execution. The results were enlightening! I decided to share the approach with my team along with an essay on the topic by Guido Van Rossem.
General Rules of Thumb by Which to Develop Loops
Never optimize before you have proven a speed bottleneck exists.</description></item><item><title>Working With File Like Objects in Lambda</title><link>/post/2021-12-30-file-like-objects-in-lambda/</link><pubDate>Thu, 30 Dec 2021 16:35:34 -0500</pubDate><guid>/post/2021-12-30-file-like-objects-in-lambda/</guid><description>I recently started working on a workflow for picking up files from S3, processing them, and writing the results to another S3 location. This is a common pattern in data processing pipelines and our team wanted to see whether we could do it using AWS serverless services. We were able to get it running via Lambda functions and event triggers published to an AWS EventHub. The entire workflow was fairly easy to stand up once we grasped how the various services worked together.</description></item><item><title>Upload a Pandas Dataframe to AWS S3 With Ease</title><link>/post/2021-08-31-upload-pandas-df-to-s3/</link><pubDate>Tue, 31 Aug 2021 12:24:01 -0400</pubDate><guid>/post/2021-08-31-upload-pandas-df-to-s3/</guid><description>Uploading a Pandas dataframe to S3 is different from writing the dataframe to a local filesystem. But have no fear! It is easy once you understand a couple of key concepts. Here is a working example using boto3.resource(&amp;quot;s3&amp;quot;) that has been tested against pandas 1.3.2. It is worth noting that the following will only work with pandas versions greater than 1.2.0.
from io import BytesIO import boto3 import pandas from pandas import util df = util.</description></item><item><title>Moving My Personal Blog From Wordpress to Hugo</title><link>/post/2021-08-16-moving-my-blog-to-hugo/</link><pubDate>Mon, 16 Aug 2021 11:13:00 -0400</pubDate><guid>/post/2021-08-16-moving-my-blog-to-hugo/</guid><description>I started the process of moving my personal blog over a year ago, when the global pandemic brought on by the COVID-19 virus sent my local area into lock down. The reasons for doing so were simple enough, my web hosting bill had grown north of $200 dollars a month for my personal blog. Don&amp;rsquo;t get me wrong, Wordpress is great! I just wanted to get my blog onto something more appropriate for the audience (read, pretty small).</description></item><item><title>Dynamically Set ORM Schemas via Sqlalchemy</title><link>/post/2021-04-03-dynamically-set-schemas-sqlalchemy/</link><pubDate>Sat, 03 Apr 2021 07:54:57 -0400</pubDate><guid>/post/2021-04-03-dynamically-set-schemas-sqlalchemy/</guid><description>Sometimes the solution to a problem is so obvious, it takes a while to figure it out. I recently stumbled on such a problem when trying to configure a set of Object Relational Mappings (ORM) to support an application with the same set of table objects across different schemas in Postgres. Developing an ORM to support this pattern, a multi-tenant database model, proved challenging because of where I started. Below, I will detail the correct way to support the multi-tenant pattern as well as various approaches I came across and why they should not be used.</description></item><item><title>A Primer on Data Normalization</title><link>/2020/11/29/a-primer-on-data-normalization/</link><pubDate>Sun, 29 Nov 2020 20:00:00 +0000</pubDate><guid>/2020/11/29/a-primer-on-data-normalization/</guid><description>Normalizing data is a common data engineering task. It prepares information to be stored in a way that minimizes duplication and is digestible by machines. It also aims to solve other problems and issues that are out of scope for this particular article but worth reading about if you find yourself struggling to understand jokes about E. F. Codd. This begs the question, why does normalization matter when entering information in a table or organizing a spreadsheet?</description></item><item><title>Deals, Deals, Deals</title><link>/2020/11/27/deals-deals-deals/</link><pubDate>Fri, 27 Nov 2020 13:37:28 +0000</pubDate><guid>/2020/11/27/deals-deals-deals/</guid><description>Wondering whether your favorite tools, services, or products are one sale this week? Below is a list of Cyber Week deals to help you get started with Data Engineering, refresh your toolbox, or launch your side project. Feel free to add to the list over on Github.</description></item><item><title>Let Pycharm Use WSL&amp;#8217;s Git Executable</title><link>/2020/08/28/let-pycharm-use-wsls-git-executable/</link><pubDate>Fri, 28 Aug 2020 16:39:19 +0000</pubDate><guid>/2020/08/28/let-pycharm-use-wsls-git-executable/</guid><description>This post is mostly for me but I ran into a ton of conflicting information while troubleshooting my Windows Subsystem for Linux (WSL) and PyCharm integration and figured it may help someone else. First things first. Versions matter! Before wasting your time trying to get Pycharm and WSL to play nicely, make sure you are running PyCharm2020.2 or greater and WSL 2. If you a) have no idea what those versions mean or b) are not sure what version you are using, allow me a chance to explain.</description></item><item><title>Speed Up Your REST Workflows with asyncio</title><link>/2020/08/01/speed-up-your-rest-workflows-with-asyncio/</link><pubDate>Sat, 01 Aug 2020 03:02:22 +0000</pubDate><guid>/2020/08/01/speed-up-your-rest-workflows-with-asyncio/</guid><description>I have been waiting for a project that would allow me to dig into the Python’s asyncio library. Recently, such a project presented itself. I was tasked with hitting a rate limited REST API with just under 4 million requests. My first attempt was simple. Gather and build a block of search queries, POST each one to the API, process the results, and finally insert them in a database. Here is what the code looked like:</description></item><item><title>How to Get the First N Bytes of a File</title><link>/2020/04/14/how-to-get-the-first-n-bytes-of-a-file/</link><pubDate>Tue, 14 Apr 2020 18:38:57 +0000</pubDate><guid>/2020/04/14/how-to-get-the-first-n-bytes-of-a-file/</guid><description>There comes a time when you just need to take a little off the top of a file, see what you are working with. That is where knowing how to use a utility like &amp;lt;a href=&amp;quot;http://man7.org/linux/man-pages/man1/head.1.html&amp;quot;&amp;gt;head&amp;lt;/a&amp;gt; can help. Just running:
Will get you
http://man7.org/linux/man-pages/man1/head.1.htmlBut what if that file does not have nice lines? Large SQL dump files come to mind. head has an answer. Use the -c flag to print the beginning bytes of a file instead of lines.</description></item><item><title>Search for a String in a list of Encrypted Values</title><link>/2020/01/30/search-for-a-string-in-a-list-of-encrypted-values/</link><pubDate>Thu, 30 Jan 2020 22:35:08 +0000</pubDate><guid>/2020/01/30/search-for-a-string-in-a-list-of-encrypted-values/</guid><description>Imagine a scenario where one party wants to check whether a name they have exists in a list of names kept by the another party. But I do not want the other party to know what name I am searching. This problem may seem unrealistic but imagine a data breach where tons of personal information is leaked. You want to check whether you were impacted in the breach but do not trust the party hosting the personal information to keep your query safe.</description></item><item><title>Your Simple Guide to Collecting Oral History</title><link>/2020/01/19/your-simple-guide-to-collecting-oral-history/</link><pubDate>Sun, 19 Jan 2020 21:25:12 +0000</pubDate><guid>/2020/01/19/your-simple-guide-to-collecting-oral-history/</guid><description>Collecting memories from people is an excellent way to celebrate the experience of others. I have found it helps me learn more about why people hold certain beliefs, how they overcame hardships, and the world we live in. Interviewing other people has helped me learn more about myself, which is why I wanted to write up a guide for collecting the stories of other people.
The most obvious aspect of collecting stories is interviewing.</description></item><item><title>Troubleshooting Windows Subsystem for Linux and SSH</title><link>/2020/01/16/setting-up-windows-subsystem-for-linux-to-ssh/</link><pubDate>Thu, 16 Jan 2020 21:51:26 +0000</pubDate><guid>/2020/01/16/setting-up-windows-subsystem-for-linux-to-ssh/</guid><description>The Windows Subsystem for Linux (WSL) is one of the best features on Windows 10. It makes development so much easier than it used to be but still has a few hiccups. Kinda like Linux, some things don’t “just work.” One pesky thing that I recently dealt with was getting SSH to work with a keypair file from WSL. Here is how to get SSH working on WSL.
Goal Given a keypair file, we want to invoke ssh from the command line and establish a tunnel to another server.</description></item><item><title>Kafkacat Amazon Workspace</title><link>/2020/01/14/kafkacat-amazon-workspace/</link><pubDate>Tue, 14 Jan 2020 16:16:49 +0000</pubDate><guid>/2020/01/14/kafkacat-amazon-workspace/</guid><description>Below are some notes on getting &amp;lt;a href=&amp;quot;https://github.com/edenhill/kafkacat#build&amp;quot;&amp;gt;kafkacat&amp;lt;/a&amp;gt; installed on an Amazon workspace with admin access.
The commands listed on the GitHub page will not work without a little preparation. A Linux Amazon Workspace image is based on Amazon Linux. Attempts to use a package manager like yum go through a plugin, amzn_workspaces_filter_updates. This filter only has a handful of packages (30 at the time of this writing) that can be pulled.</description></item><item><title>Processing Audio Files with Amazon Transcribe</title><link>/2019/12/31/processing-audio-files-with-amazon-transcribe/</link><pubDate>Tue, 31 Dec 2019 21:41:36 +0000</pubDate><guid>/2019/12/31/processing-audio-files-with-amazon-transcribe/</guid><description>I have been working on collecting a family’s oral history for the past few months. During the process I took notes with simple descriptions of what the speaker was describing or telling and a rough timestamp of when in the file the conversation took place. After collecting hours of stories, I realized that having a transcription would make things much easier to search and perhaps more useful to those interested in these particular histories.</description></item><item><title>Quickly Find Large Files On Windows File System</title><link>/2019/12/18/quickly-find-large-files-on-windows-file-system/</link><pubDate>Wed, 18 Dec 2019 17:11:48 +0000</pubDate><guid>/2019/12/18/quickly-find-large-files-on-windows-file-system/</guid><description>Once a year I need to free up space on my work machine. Once a year I find myself searching for an efficient way to identify the largest files that I do not need any longer without installing third party software. Here is the solution I stumbled on this year and it couldn’t be simpler.
Open File Explorer Navigate to the drive you want to search. Normally, C:\ Type “size:gigantic” in the search bar Wait for the search to complete Sort the results by size This search will scan your computer’s file system for files that are larger than 128mb.</description></item><item><title>A Simple Progress Bar in Python</title><link>/2019/04/18/a-simple-progress-bar-in-python/</link><pubDate>Thu, 18 Apr 2019 18:33:32 +0000</pubDate><guid>/2019/04/18/a-simple-progress-bar-in-python/</guid><description>Recently, I have been working with the Requestslibrary in Python. I wrote a simple function to pull down a file that took more than a minute to download. While waiting for the download to complete I realized it would be nice to have some insight into the download’s progress. A quick search on StackOverflow led to an excellent example. Below is a simple way to display a progress bar while downloading a file.</description></item><item><title>Logic for Artificial Intelligence</title><link>/2018/10/18/logic-for-artificial-intelligence/</link><pubDate>Thu, 18 Oct 2018 21:08:52 +0000</pubDate><guid>/2018/10/18/logic-for-artificial-intelligence/</guid><description>Patrick Winston, Artificial Intelligence, pp 283Logic in artificial intelligence can be used to help an agent create rules of inference. It provides a formal framework for creating if-then statements. Formal logic statements can be difficult for beginners because of the symbols and vocabulary used. Below is a cheat sheet for some of the basic symbols and definitions.
&amp;lt;td&amp;gt; Definition &amp;lt;/td&amp;gt; &amp;lt;td&amp;gt; Logical conjunction. In most instances it will be used as an AND operator.</description></item><item><title>Qualia</title><link>/2018/10/10/qualia/</link><pubDate>Wed, 10 Oct 2018 03:36:29 +0000</pubDate><guid>/2018/10/10/qualia/</guid><description>Have you ever tried to describe the color red to someone who suffers from protanopia, deuteranopia, protanomaly, or deuteranomaly? It is nearly impossible since those who are red-green color blind are missing the corresponding photoreceptors. The experience of seeing red is so familiar to those who have experienced it. And that type of experience, one which is difficult to communicate, does not change based on other experiences, is unique to the individual experiencing it, and immediately recognized, is qualia.</description></item><item><title>A Brief Introduction to Bayes&amp;#8217; Theorem</title><link>/2018/08/22/a-brief-introduction-to-bayes-theorem/</link><pubDate>Wed, 22 Aug 2018 13:13:41 +0000</pubDate><guid>/2018/08/22/a-brief-introduction-to-bayes-theorem/</guid><description>Bayes’ Theorem stated is, “the conditional probability of A given B is the conditional probability of B given A scaled by the relative probability of A compared to B”. I find it easier to understand through a practical explanation. Let’s say you are having a medical test performed at the recommendation of your doctor, who recommends tests to everyone because they get a nice kickback and college tuition is not cheap!</description></item></channel></rss>